# Weak Links in LinkedIn: Enhancing Fake Profile Detection in the Age of LLMs

This repository contains the code and resources for our research on detecting fake LinkedIn profiles, with a particular focus on profiles generated by Large Language Models (LLMs) like GPT-3.5 and GPT-4.

## Instructions to use the code

### 1. Data Preparation
* `data_cleaning.ipynb`: Data preprocessing and cleaning pipeline to prepare datasets for experiments.
   * Resolves formatting inconsistencies
   * Validates essential fields and assigns default values for missing fields
   * Outputs: `cleaned_profiles.csv`

### 2. Embedding Generation and Analysis
* `embeddings_pca_variance_new.ipynb`: Analysis of embedding models and dimensionality reduction using PCA.
   * Evaluates multiple embedding models (BERT, RoBERTa, Flair, GloVe, DeBERTa, ModernBERT)
   * Conducts PCA analysis to determine optimal number of components
   * Analyzes the relationship between explained variance and model performance

### 3. Model Training and Evaluation
* `baseline_accuracy_classifier_calibration.ipynb`: Main notebook for baseline model training and evaluation.
   * Implements Section Tag Embeddings (STE) with textual and numerical features
   * Evaluates multiple classifiers (Random Forest, Logistic Regression, SVM, KNN, XGBoost, CatBoost)
   * Performs classifier calibration analysis using Brier scores and reliability curves
   * Selects the best performing model combinations

### 4. Adversarial Testing
* `adversarial_data.ipynb`: Generates additional synthetic profiles using GPT-4 Turbo for robustness evaluation.
   * Outputs: `generated_profiles_NEW.csv`


* `adversarial_training_crossval_tuning.ipynb`: Implementation of adversarial training with cross-validation.
   * Trains models with exposure to LLM-generated profiles
   * Performs hyperparameter tuning using Bayesian Optimization and Genetic Algorithms
   * Evaluates model robustness across different adversarial scenarios

* `brier_far_analysis.ipynb`: Analysis of the relationship between Brier scores and False Accept Rates.
   * Examines correlation between model calibration and robustness
   * Evaluates how well-calibrated models perform against adversarial examples

### 5. Benchmarking
* `gpt_baseline.ipynb`: Benchmarks GPT-4's profile classification performance.
   * Implements zero-shot and few-shot classification approaches
   * Compares GPT-4's detection capabilities to automated systems

* `human_baseline.ipynb`: Analyzes human performance in fake profile detection.
   * Processes results from 30 human evaluators
   * Computes metrics for three-class and binary classification tasks

### 6. Datasets
* `cleaned_profiles.csv`: Cleaned dataset containing profiles from the original study.
   * 1,800 legitimate LinkedIn profiles (LLPs)
   * 600 manually created fake profiles (FLPs)
   * 1,200 GPT-3.5 generated profiles (GPT3.5Ps)

* `generated_profiles_NEW.csv`: Additional dataset with 600 profiles generated using GPT-4 Turbo.
   * Created using few-shot prompting with GPT-4
   * Diverse across regions, industries, career stages, and organization types
 

|    Model   |  Train Scenario  | Test Baseline | Test GPTv1 | Test GPTv2 | Test GPTv1v2 |
|:----------:|:----------------:|:-------------:|:----------:|:----------:|:------------:|
| roberta    | baseline         | 95.86%        | 78.51%     | 79.29%     | 69.89%       |
| roberta    | gptv1_assisted   | 96.14%        | 97.41%     | 90.12%     | 93.03%       |
| roberta    | gptv2_assisted   | 96.13%        | 80.13%     | 96.97%     | 83.77%       |
| roberta    | gptv1v2_assisted | 96.12%        | 97.41%     | 96.86%     | 97.74%       |
| deberta    | baseline         | 97.07%        | 78.46%     | 77.46%     | 67.88%       |
| deberta    | gptv1_assisted   | 96.52%        | 97.69%     | 90.54%     | 93.34%       |
| deberta    | gptv2_assisted   | 96.38%        | 79.02%     | 96.97%     | 82.80%       |
| deberta    | gptv1v2_assisted | 96.80%        | 97.78%     | 97.18%     | 97.90%       |
| modernbert | baseline         | 95.71%        | 77.98%     | 81.64%     | 71.19%       |
| modernbert | gptv1_assisted   | 95.99%        | 97.31%     | 89.55%     | 92.64%       |
| modernbert | gptv2_assisted   | 96.26%        | 79.08%     | 97.08%     | 82.97%       |
| modernbert | gptv1v2_assisted | 96.56%        | 97.69%     | 97.30%     | 98.05%       |
| flair      | baseline         | 96.39%        | 78.95%     | 84.73%     | 73.82%       |
| flair      | gptv1_assisted   | 96.81%        | 97.87%     | 88.94%     | 92.26%       |
| flair      | gptv2_assisted   | 96.80%        | 79.44%     | 97.51%     | 83.28%       |
| flair      | gptv1v2_assisted | 96.94%        | 97.96%     | 97.62%     | 98.29%       |
