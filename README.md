# Weak Links in LinkedIn: Enhancing Fake Profile Detection in the Age of LLMs

This repository contains the code and resources for our research on detecting fake LinkedIn profiles, with a particular focus on profiles generated by Large Language Models (LLMs) like GPT-3.5 and GPT-4.

## Instructions to use the code

### 1. Data Preparation
* `data_cleaning.ipynb`: Data preprocessing and cleaning pipeline to prepare datasets for experiments.
   * Resolves formatting inconsistencies
   * Validates essential fields and assigns default values for missing fields
   * Outputs: `cleaned_profiles.csv`

### 2. Embedding Generation and Analysis
* `embeddings_pca_variance_new.ipynb`: Analysis of embedding models and dimensionality reduction using PCA.
   * Evaluates multiple embedding models (BERT, RoBERTa, Flair, GloVe, DeBERTa, ModernBERT)
   * Conducts PCA analysis to determine optimal number of components
   * Analyzes the relationship between explained variance and model performance

### 3. Model Training and Evaluation
* `baseline_accuracy_classifier_calibration.ipynb`: Main notebook for baseline model training and evaluation.
   * Implements Section Tag Embeddings (STE) with textual and numerical features
   * Evaluates multiple classifiers (Random Forest, Logistic Regression, SVM, KNN, XGBoost, CatBoost)
   * Performs classifier calibration analysis using Brier scores and reliability curves
   * Selects the best performing model combinations

### 4. Adversarial Testing
* `adversarial_data.ipynb`: Generates additional synthetic profiles using GPT-4 Turbo for robustness evaluation.
   * Outputs: `generated_profiles_NEW.csv`


* `adversarial_training_crossval_tuning.ipynb`: Implementation of adversarial training with cross-validation.
   * Trains models with exposure to LLM-generated profiles
   * Performs hyperparameter tuning using Bayesian Optimization and Genetic Algorithms
   * Evaluates model robustness across different adversarial scenarios

* `brier_far_analysis.ipynb`: Analysis of the relationship between Brier scores and False Accept Rates.
   * Examines correlation between model calibration and robustness
   * Evaluates how well-calibrated models perform against adversarial examples

### 5. Benchmarking
* `gpt_baseline.ipynb`: Benchmarks GPT-4's profile classification performance.
   * Implements zero-shot and few-shot classification approaches
   * Compares GPT-4's detection capabilities to automated systems

* `human_baseline.ipynb`: Analyzes human performance in fake profile detection.
   * Processes results from 30 human evaluators
   * Computes metrics for three-class and binary classification tasks

### 6. Datasets
* `cleaned_profiles.csv`: Cleaned dataset containing profiles from the original study.
   * 1,800 legitimate LinkedIn profiles (LLPs)
   * 600 manually created fake profiles (FLPs)
   * 1,200 GPT-3.5 generated profiles (GPT3.5Ps)

* `generated_profiles_NEW.csv`: Additional dataset with 600 profiles generated using GPT-4 Turbo.
   * Created using few-shot prompting with GPT-4
   * Diverse across regions, industries, career stages, and organization types
